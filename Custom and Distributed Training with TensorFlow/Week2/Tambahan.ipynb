{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "buried-stranger",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "#define Network\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "def base_model():\n",
    "    inputs = tf.keras.Input(shape=(784,),name = \"inputs\")\n",
    "    x = tf.keras.layers.Dense(64, activation = tf.nn.relu, name=\"dense1\")(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation = tf.nn.relu, name=\"dense2\")(x)\n",
    "    outputs = tf.keras.layers.Dense(10, activation=tf.nn.softmax, name=\"predictions\")(x)\n",
    "    model = tf.keras.Model(inputs,outputs)\n",
    "    return model\n",
    "base_model()\n",
    "\n",
    "\n",
    "\n",
    "training_data = tfds.load(\"fashion_mnist\", split=\"train\")\n",
    "test_data = tfds.load(\"fashion_mnist\",split=\"test\")\n",
    "\n",
    "def format_image(data):\n",
    "    image = data[\"image\"]\n",
    "    image = tf.reshape(image, [-1])\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image/ 255.0\n",
    "\n",
    "    return image, data[\"label\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "another-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2 5], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [6 7]\n",
      " [7 2]\n",
      " [3 5]\n",
      " [4 6]], shape=(5, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "constant = tf.constant([[2,4,6,7,7],[2,3,5,4,6]])\n",
    "print(tf.shape(constant))\n",
    "print(tf.reshape(constant,[5,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "joint-bryan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 784), dtype=tf.float32, name=None),\n",
       " TensorSpec(shape=(None,), dtype=tf.int64, name=None))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(training_data.element_spec)\n",
    "training_data = training_data.map(format_image)\n",
    "test_data = test_data.map(format_image)\n",
    "train = training_data.shuffle(buffer_size=1024).batch(64)\n",
    "test = test_data.batch(64)\n",
    "train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thrown-bread",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x00000284E5537828>\n"
     ]
    }
   ],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer =  tf.keras.optimizers.Adam()\n",
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adjustable-scout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = base_model()\n",
    "len(model.trainable_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "flush-weight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for _ in train:\n",
    "    i += 1\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "funny-respect",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_metrics = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metrics = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "color-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x) # Do prediciton\n",
    "        loss_value = loss(y_pred=logits, y_true=y) #Calculate Losses\n",
    "    \n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights) # Calculate Gradients\n",
    "    optimizer.apply_gradients(zip(gradients,model.trainable_weights)) # Tunning Losses\n",
    "    \n",
    "    return logits, loss_value\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "conventional-fraction",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Nyoba 99:  99%|█████████▉| 99/100"
     ]
    }
   ],
   "source": [
    "pb = tqdm(total=100,position=0,leave=True, bar_format= \"{l_bar}{bar}| {n_fmt}/{total_fmt}\")\n",
    "for i in range(100):\n",
    "    \n",
    "    pb.set_description(\"Nyoba %d\" % (i))\n",
    "    pb.update()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "extreme-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_one_epoch():\n",
    "    losses = []\n",
    "    pb = tqdm(total = len(list(enumerate(train))) ,position=0,leave=True, bar_format=\"{l_bar}{bar}| {n_fmt}/{total_fmt}\")\n",
    "    for step, (x_batch_train,y_batch_train) in enumerate(train):\n",
    "\n",
    "        logits, loss_value = apply_gradient(optimizer, model, x_batch_train, y_batch_train)\n",
    "        losses.append(loss_value)\n",
    "        train_acc_metrics(y_batch_train,logits)\n",
    "        pb.set_description(\"Training Loss for Step %d: %.4f\" % ( int(step),float(loss_value)))\n",
    "        pb.update()\n",
    "    return losses\n",
    "\n",
    "def do_validation():\n",
    "    losses = []\n",
    "    for x_val ,y_val in test:\n",
    "        \n",
    "        val_logits = model(x_val)\n",
    "        val_loss = loss(y_true=y_val, y_pred=val_logits)\n",
    "        losses.append(val_loss)\n",
    "        val_acc_metrics(y_val,val_logits)\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "consolidated-grant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of the epoch : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.4369: 100%|█████████▉| 937/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 : Train lossL 0.4811 Validation Loss : 0.4326 , Train acc : 0.8308 Val acc : 0.8359\n",
      "Start of the epoch : 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.4369: 100%|██████████| 938/938\n",
      "Training Loss for Step 937: 0.3722: 100%|██████████| 938/938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 : Train lossL 0.3619 Validation Loss : 0.3767 , Train acc : 0.8671 Val acc : 0.8612\n",
      "Start of the epoch : 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.3031: 100%|██████████| 938/938\n",
      "Training Loss for Step 119: 0.3883:  13%|█▎        | 119/938\n",
      "Training Loss for Step 202: 0.2175:  22%|██▏       | 203/938\n",
      "Training Loss for Step 937: 0.3511: 100%|█████████▉| 937/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 : Train lossL 0.3295 Validation Loss : 0.3629 , Train acc : 0.8784 Val acc : 0.8675\n",
      "Start of the epoch : 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.3208: 100%|██████████| 938/938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 : Train lossL 0.3115 Validation Loss : 0.3570 , Train acc : 0.8847 Val acc : 0.8675\n",
      "Start of the epoch : 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.2267: 100%|█████████▉| 937/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 : Train lossL 0.2966 Validation Loss : 0.3726 , Train acc : 0.8904 Val acc : 0.8648\n",
      "Start of the epoch : 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.2267: 100%|██████████| 938/938\n",
      "Training Loss for Step 937: 0.2630: 100%|█████████▉| 937/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 : Train lossL 0.2841 Validation Loss : 0.3541 , Train acc : 0.8948 Val acc : 0.8695\n",
      "Start of the epoch : 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.2630: 100%|██████████| 938/938\n",
      "Training Loss for Step 937: 0.1997: 100%|██████████| 938/938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 : Train lossL 0.2728 Validation Loss : 0.3578 , Train acc : 0.8973 Val acc : 0.8721\n",
      "Start of the epoch : 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.2183: 100%|█████████▉| 937/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 : Train lossL 0.2627 Validation Loss : 0.3645 , Train acc : 0.9021 Val acc : 0.8714\n",
      "Start of the epoch : 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.2183: 100%|██████████| 938/938\n",
      "Training Loss for Step 937: 0.3560: 100%|█████████▉| 937/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 : Train lossL 0.2538 Validation Loss : 0.3432 , Train acc : 0.9064 Val acc : 0.8755\n",
      "Start of the epoch : 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Loss for Step 937: 0.3560: 100%|██████████| 938/938\n",
      "Training Loss for Step 937: 0.5484: 100%|██████████| 938/938"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 : Train lossL 0.2475 Validation Loss : 0.3485 , Train acc : 0.9072 Val acc : 0.8778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "EPOCHS = 10\n",
    "epochs_val_losses , epochs_train_losses = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Start of the epoch : %d\" % (epoch))\n",
    "    losses_train = train_data_one_epoch()\n",
    "    train_acc = train_acc_metrics.result()\n",
    "    \n",
    "    losses_val = do_validation()\n",
    "    val_acc = val_acc_metrics.result()\n",
    "    #print(len(losses_train))#938 < TOtal Batches >\n",
    "    losses_train_mean = np.mean(losses_train)\n",
    "    losses_val_mean = np.mean(losses_val)\n",
    "    epochs_val_losses.append(losses_val_mean)\n",
    "    epochs_train_losses.append(losses_train_mean)\n",
    "    \n",
    "    print(\"\\nEpoch %s : Train lossL %.4f Validation Loss : %.4f , Train acc : %.4f Val acc : %.4f\" % (epoch, losses_train_mean, losses_val_mean,train_acc,val_acc))\n",
    "    \n",
    "    train_acc_metrics.reset_states()\n",
    "    val_acc_metrics.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-complaint",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "national-subcommittee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable               Type                             Data/Info\n",
      "-----------------------------------------------------------------\n",
      "EPOCHS                 int                              10\n",
      "apply_gradient         function                         <function apply_gradient at 0x00000284E57A6A60>\n",
      "base_model             function                         <function base_model at 0x00000284E6B7EBF8>\n",
      "constant               EagerTensor                      tf.Tensor(\\n[[2 4 6 7 7]\\<...>hape=(2, 5), dtype=int32)\n",
      "do_validation          function                         <function do_validation at 0x00000284E57A6268>\n",
      "epoch                  int                              9\n",
      "epochs_train_losses    list                             n=10\n",
      "epochs_val_losses      list                             n=10\n",
      "format_image           function                         <function format_image at 0x00000284E6BF12F0>\n",
      "i                      int                              99\n",
      "loss                   SparseCategoricalCrossentropy    <tensorflow.python.keras.<...>ct at 0x00000284E5537128>\n",
      "losses_train           list                             n=938\n",
      "losses_train_mean      float32                          0.24750963\n",
      "losses_val             list                             n=157\n",
      "losses_val_mean        float32                          0.34847662\n",
      "model                  Model                            <tensorflow.python.keras.<...>ct at 0x00000284E6DD6908>\n",
      "np                     module                           <module 'numpy' from 'C:\\<...>ges\\\\numpy\\\\__init__.py'>\n",
      "optimizer              Adam                             <tensorflow.python.keras.<...>ct at 0x00000284E5537828>\n",
      "pb                     tqdm                             Nyoba 99: 100%|██████████| 100/100\n",
      "test                   BatchDataset                     <BatchDataset shapes: ((N<...>: (tf.float32, tf.int64)>\n",
      "test_data              _OptionsDataset                  <_OptionsDataset shapes: <...>.uint8, label: tf.int64}>\n",
      "tf                     module                           <module 'tensorflow' from<...>tensorflow\\\\__init__.py'>\n",
      "tfds                   module                           <module 'tensorflow_datas<...>w_datasets\\\\__init__.py'>\n",
      "tqdm                   type                             <class 'tqdm.std.tqdm'>\n",
      "train                  BatchDataset                     <BatchDataset shapes: ((N<...>: (tf.float32, tf.int64)>\n",
      "train_acc              EagerTensor                      tf.Tensor(0.90725, shape=(), dtype=float32)\n",
      "train_acc_metrics      SparseCategoricalAccuracy        <tensorflow.python.keras.<...>ct at 0x00000284E574A4A8>\n",
      "train_data_one_epoch   function                         <function train_data_one_<...>ch at 0x00000284E6D46950>\n",
      "training_data          _OptionsDataset                  <_OptionsDataset shapes: <...>.uint8, label: tf.int64}>\n",
      "val_acc                EagerTensor                      tf.Tensor(0.8778, shape=(), dtype=float32)\n",
      "val_acc_metrics        SparseCategoricalAccuracy        <tensorflow.python.keras.<...>ct at 0x00000284E574AAC8>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-cassette",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-community",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-cologne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-connectivity",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-combine",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-fluid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
